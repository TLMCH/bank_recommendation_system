# Проект: Создание рекомендательной системы для банковских продуктов.

Цель проекта - на основе ежемесячных данных о клиентах предсказать, какие финансовые продукты могут быть им интересны в будущем.

Практическая направленность проекта — приближение к реальной задаче персонализированных рекомендаций в банках, с учётом рисков, поведения клиентов и разнообразия банковских услуг. Я провёл исследование данных (EDA), построил пайплайн подготовки данных, выбрал и обучил модели, задеплоил сервис с использованием Docker и FastAPI, настроил MLflow для трекинга экспериментов и добавил мониторинг ключевых метрик.

Результатом стала полнофункциональная система, имитирующая реальную рекомендательную платформу: от анализа и обучения модели до API-сервиса и мониторинга в проде.

### Для настройки виртуального окружения необходимо выполнить следующие команды:

Обновление локального индекса пакетов:

```
sudo apt-get update
```

Установка расширения для виртуального пространства:

```
sudo apt-get install python3.10-venv
```

Создание виртуального пространства:

```
python3.10 -m venv .venv_project_name
```

Запуск виртуального пространства:

```
source .venv_project_name/bin/activate
```

Установка библиотек:

```
pip install -r requirements.txt
```


#### Для загрузки данных выполните в терминале код:

```
python3 download_dataset.py
```


### Выводы по EDA

- Все данные написаны на испанском языке

- В датасете почти миллион уникальных пользователей, что очень мало относительно всей выборки.

- В данных много пропусков. В столбцах ult_fec_cli_1t(Последняя дата, когда клиент был премиальным) и conyuemp(1, если клиент супруг(а) работника) практически нет данных. В первом пропущенные значения означают отсутствие даты, можно было бы заполнить 0 пропуски, а даты заменить на 1, но эта информация есть в столбце indrel_1mes, значит можно удалить этот столбец. 

- В столбце conyuemp N скорее всего испанское No, тогда S - Si. Если это так, то среди клиентов банка всего 17 супругов работников. Это слишком малая часть клиентов и от этих данных можно отказаться.

- В 27734 строках пропущены значения очти во всех или во всех столбцах, их нужно удалить. 

- В столбце ind_empleado есть неизвестная категория S. Скорее всего это должно быть P (статус не определён). Нужно заменить S на P.

- В столбце indrel_1mes есть ошибка с записью классов, нужно заменить все float на int. Для пропущенных данных создам новый класс - N.

- В столбце tiprel_1mes изначально есть 4 значения с классом N, которого быть не должно. Поступлю с этим столбцом также как с предыдущим и пропускам присвою класс N.

- В столбце cod_prov 65856 пропусков, как и в столбце nomprov с названием провинции. Все пропуски в этих двух столбцах я заполню наиболее частым классом.

- В столбце segmento заполню пропуски наиболее распространённым классом и переименую значения, убрав из них цифры.

- Все числовые данные в порядке, кроме столбца tipodom, в котором все значения 1 и столбца renta с аномально большими значениями.

- В столбце с возрастом клиента данные записаны как строки. Нужно привести их к типу int. Со столбцом antiguedad возникла такая же проблема.

- Корреляции в числовых признаках нет.

- Нужно заменить тип данных в столбцах с датами на datetime.

- Во всех бинарных признаках кроме пола наблюдается сильный дисбаланс. В будущем нужно будет подумать использовать их или нет.

- Столбец fecha_dato - это колонка для разделения таблицы. Я так понимаю что это нужно для разделения на train и test.

- Много клиентов стало приходить в банк примерно после 2011 года. 

Все преобразования данных на этом этапе были также записаны в файле preprocessing.ipynb. В указанном файле обработанныые данные были сохранены в data/preprocessed_data.parquet.


### Подготовка инфраструктуры

Скрипт для запска MLflow находится в файле run_mlflow_server.sh. Для его запуска нужно ввести команду:

```
sh run_mlflow_server.sh
```


### Метрики и способы решения задачи

Персональные рекоммендации получу при помощи als, а затем отранжирую их используя catboost.

В качестве метрик буду оценивать покрытие и новизну, так как нужно стараться предлагать пользователям как можно больше продуктов банка. Помимо этого точность рекомендаций я буду оценивать, используя precision и recall.


### Моделирование

В файле recommendations.ipynb нахоится код для построения моделей и получения рекомендаций. Итоговые рекомендации показали хорошие значения метрик:

- Precision: 0.9005432056036121
- Recall: 0.9881917080848547
- Coverage: 1.0
- Novelty: 0.6687687678606528

Модель оказалась точной, а рекомендаций покрывают 100% продуктов банка, при этом достаточно часто рекомендуют пользователям новые продукты.

Файлы с моделями и рекомендациями хранятся в папке models_and_recommendations. Файлы с финальными рекомендациями и топом популярных лежат по пути services/recs. Такое размещение выбрано для дальнейшего использования рекомендаций в сервисе.

Название эксперимента в MLflow - Bank_recommendations


### Продуктивизация

Все файлы для работы с сервисом находятся в папке services.

Код с веб-сервисом находится в файле recommendation_service.py, а класс для выдачи рекомендаций в файле recommendations.py. 

POST-запрос "/recommendations" принимает на вход два параметра: user_id и k. Параметр k отвечает за количество рекомендуемых продуктов (ставить значение больше 5 не имеет смысла, так как персональные рекомендации ограничены именно этим значением). 

Команда перехода в нужную директорию:

```
cd services
```

Команда для запуска микросервиса в режиме docker compose:

```
docker compose up --build
```

Запуск скрипта для симуляции нагрузки (генерируются 5 запросов в течение 105 секунд):

```
python3 test_requsts.py
```

Адреса сервисов:
- микросервис: http://localhost:4601
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3000


### Мониторинг

Метрики описаны в файле Monitoring.md.

В файле services/dashboard.json находится конфигурация дашборда в Grafana.
